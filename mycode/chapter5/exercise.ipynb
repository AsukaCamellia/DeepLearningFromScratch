{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "乘法层（MulLayer）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "\n",
    "    #初始化、前向传播、反向传播\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out = x*y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    #dout为上游传来的导数\n",
    "    def backward(self,dout):\n",
    "        dx = dout*self.y\n",
    "        dy = dout*self.x\n",
    "        \n",
    "        return dx,dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220.00000000000003"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "apple_price = mul_apple_layer.forward(apple,apple_num)\n",
    "price = mul_tax_layer.forward(apple_price,tax)\n",
    "\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2, 110.00000000000001, 200)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dprice = 1\n",
    "dapple_price,dtax = mul_tax_layer.backward(dprice)\n",
    "dapple,dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "\n",
    "dapple,dapple_num,dtax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加法层（AddLayer）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        out = x+y\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = dout * 1\n",
    "        dy = dout * 1\n",
    "\n",
    "        return dx,dy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_sumtax_layer = MulLayer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715.0000000000001, 2.2, 110.00000000000001, 3.3000000000000003, 165.0, 650)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_price = mul_apple_layer.forward(apple,apple_num)\n",
    "orange_price = mul_orange_layer.forward(orange,orange_num)\n",
    "all_price = add_apple_orange_layer.forward(apple_price,orange_price)\n",
    "price = mul_tax_layer.forward(all_price,tax)\n",
    "\n",
    "dprice = 1\n",
    "dall_price,dtax = mul_tax_layer.backward(dprice)\n",
    "dapple_price,dorange_price = add_apple_orange_layer.backward(dall_price)\n",
    "dorange,dorange_num = mul_orange_layer.backward(dorange_price)\n",
    "dapple,dapple_num = mul_apple_layer.backward(dapple_price)\n",
    "\n",
    "price,dapple,dapple_num,dorange,dorange_num,dtax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    def __init__(self) -> None:\n",
    "        self.mask = None\n",
    "\n",
    "    #传入的x不是单个值 简单比大小就可以的 所以需要mask进行处理\n",
    "    def forward(self,x):\n",
    "        self.mask = (x<=0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "\n",
    "    #mask是由True/False构成的Numpy数组，会把正向传播时\n",
    "    #输入x中<=0的地方保存为True，其他地位False\n",
    "    #mask和x尺寸一样\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1. , -0.5],\n",
       "        [-2. ,  3. ]]),\n",
       " array([[False,  True],\n",
       "        [ True, False]]),\n",
       " array([-0.5, -2. ]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1.0,-0.5],[-2.0,3.0]])\n",
    "mask = (x<=0)\n",
    "x,mask,x[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self) -> None:\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = 1/(1+np.exp(-x))\n",
    "        return out\n",
    "    \n",
    "    def backward(self,dout):\n",
    "        dx = dout * self.out * (1-self.out)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affine层\\\n",
    "神经网络的正向传播中进行的矩阵乘积运算在几何领域被称为仿射变换 因此称为Affine层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0,  0],\n",
       "        [10, 10, 10]]),\n",
       " array([[ 1,  2,  3],\n",
       "        [11, 12, 13]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dot_w = np.array([[0,0,0],[10,10,10]])\n",
    "b = np.array([1,2,3])\n",
    "x_dot_w,x_dot_w+b\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵的导数 和矩阵的尺寸一样 所以偏置b的导数 是把dy第0轴进行求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self,w,b) -> None:\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.x = None\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        out = np.dot(x,self.w)+self.b\n",
    "\n",
    "    def backward(self,dout):\n",
    "        dx = np.dot(dout,self.w.T)\n",
    "        self.dw = np.dot(self.x.T,dout)\n",
    "        self.db = np.sum(dout,axis=0)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        max_x = np.max(x,axis=0)\n",
    "        x = x-max_x\n",
    "        y = np.exp(x)/np.sum(np.exp(x),axis=0)\n",
    "\n",
    "        return y.T\n",
    "    \n",
    "    max_x = np.max(x)\n",
    "    x = x-max_x\n",
    "    y = np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "def cross_entropy_error(y,t):\n",
    "    delta = 1e-4\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(1,y.size)\n",
    "        t = t.reshape(1,t.size)\n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "\n",
    "    if y.size == t.size:\n",
    "        t = np.argmax(t,axis=1)#t = t.argmax(axis = 1)\n",
    "\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t]+delta))/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self) -> None:\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "\n",
    "    def forward(self,x,t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y,self.t)\n",
    "\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self,dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t)/batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4020871865.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[34], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    def __in\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerNet:\n",
    "    def __ini"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
